FROM bitnami/spark:3.4.2

ENV HADOOP_VERSION=3.2.1
ENV HADOOP_HOME=/opt/hadoop
ENV PATH=/opt/conda/bin:$PATH
ENV SPARK_DIST_CLASSPATH="/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*"

# Install wget and bzip2 for Miniconda
USER root
RUN install_packages apt-utils wget bzip2 curl && \
    wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh && \
    bash /tmp/miniconda.sh -b -p /opt/conda && \
    rm /tmp/miniconda.sh && \
    /opt/conda/bin/conda init bash && \
    /opt/conda/bin/conda create -y -n pyspark38 python=3.8 && \
    /opt/conda/bin/conda run -n pyspark38 pip install pyspark==3.4.2 kafka-python && \
    curl -fL -o hadoop-${HADOOP_VERSION}.tar.gz https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz -C /opt && \
    mv /opt/hadoop-${HADOOP_VERSION} $HADOOP_HOME && \
    rm hadoop-${HADOOP_VERSION}.tar.gz && \
    chown -R 1001:0 /opt/conda && \
    chown -R 1001:0 /opt/hadoop

# Optionally, set bash as the default shell for interactive use
SHELL ["/bin/bash", "-c"]

USER 1001

# Instructions:
# To use the container as a development environment, run:
#   docker run -it --user 1001 <image> bash
# Then you can use conda commands, e.g.:
#   conda create -n myenv python=3.9
#   conda activate myenv
